{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b36fe48a",
   "metadata": {},
   "source": [
    "# Data Workshop 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c953193",
   "metadata": {},
   "source": [
    "**Instructor:** Jared Brzenski (jabrzenski@ucsd.edu)\n",
    "\n",
    "**TAs:** Tommy Stone           (thstone@ucsd.edu)\n",
    "\n",
    "This script reviews how to:\n",
    "- import text data\n",
    "- clean data (remove NaNs, fill missing values, evenly space values)\n",
    "- Do spectral analysis on the cleaned data\n",
    "\n",
    "\n",
    "This can be run as MATLAB or Python, depending on the environment chosen.\n",
    "\n",
    "[MATLAB](#MATLAB) is shown first, with MATLAB code blocks starting with the **% MATLAB** header.\n",
    "\n",
    "[Python](#Python) is shown second, starting from the [**Python**](#Python) header and has **# Python** at the beginning of the code blocks.\n",
    "If you want to skip to Python, scroll down to the [**Python**](#Python) header!\n",
    "\n",
    "For MATLAB, run ```pip install jupyter-matlab-proxy``` in your environment and activate MATLAB in the upper right corner.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be50903",
   "metadata": {},
   "source": [
    "## MATLAB \n",
    "\n",
    "### Import Raw Data\n",
    "Lets say we are given the task of analyzing the hsitorical data fro mthe water gauge station at the [Prado Dam in Los Angeles](https://waterdata.usgs.gov/monitoring-location/USGS-11074000/#dataTypeId=continuous-00065-0&period=P7D).\n",
    "\n",
    "We want to download the [data](data/PradoDam.txt), clean it, and do some spectral analysis on it to see if there is anything interesting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8b2ee",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "If we do a quick check of the file, we note there is a giant header, then some columns of data.\n",
    "```\n",
    "# ---------------------------------- WARNING ----------------------------------------\n",
    "# Some of the data that you have obtained from this U.S. Geological Survey database\n",
    "# may not have received Director's approval. Any such data values are qualified\n",
    "# as provisional and are subject to revision. Provisional data are released on the\n",
    "# condition that neither the USGS nor the United States Government may be held liable\n",
    "# for any damages resulting from its use.\n",
    "#\n",
    "# Additional info: https://help.waterdata.usgs.gov/policies/provisional-data-statement\n",
    "#\n",
    "# File-format description:  https://help.waterdata.usgs.gov/faq/about-tab-delimited-output\n",
    "# Automated-retrieval info: https://help.waterdata.usgs.gov/faq/automated-retrievals\n",
    "#\n",
    "# Contact:   gs-w_support_nwisweb@usgs.gov\n",
    "# retrieved: 2020-04-29 18:30:02 EDT       (caww01)\n",
    "#\n",
    "# Data for the following 1 site(s) are contained in this file\n",
    "#    USGS 11074000 SANTA ANA R BL PRADO DAM CA\n",
    "# -----------------------------------------------------------------------------------\n",
    "#\n",
    "# Data provided for site 11074000\n",
    "#            TS   parameter     statistic     Description\n",
    "#          8183       00060     00003     Discharge, cubic feet per second (Mean)\n",
    "#\n",
    "# Data-value qualification codes included in this output:\n",
    "#     A  Approved for publication -- Processing and review completed.\n",
    "#     P  Provisional data subject to revision.\n",
    "#     e  Value has been estimated.\n",
    "# \n",
    "agency_cd\tsite_no\tdatetime\t8183_00060_00003\t8183_00060_00003_cd\n",
    "5s\t15s\t20d\t14n\t10s\n",
    "USGS\t11074000\t1940-09-30\t51.0\tA\n",
    "USGS\t11074000\t1940-10-01\t47.0\tA\n",
    "USGS\t11074000\t1940-10-02\t47.0\tA\n",
    "USGS\t11074000\t1940-10-03\t47.0\tA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27df20-b2e9-4c36-ae28-8e3828df4cb9",
   "metadata": {},
   "source": [
    "This tells us the pertinent information about the file, where it came from, and what format the data displayed is in.\n",
    "\n",
    "In MATLAB, we can load this data in by giving the filename of the data location, and using readtable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76be2c-0024-4690-a1d2-6db0af119162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "% MATLAB\n",
    "% read in a text file\n",
    "\n",
    "filename = 'data/PradoDam.txt';\n",
    "\n",
    "% Offer a helpful hint if we cant find the file\n",
    "[path, name, ext] = fileparts(filename);\n",
    "if ext ~= '.txt'\n",
    "    fprint(\"Wrong file extension given.\\n\");\n",
    "    return;\n",
    "end\n",
    "\n",
    "% We could read in the data raw with\n",
    "% ff = importdata(filename);\n",
    "\n",
    "% Or, read it in as a table with\n",
    "f =  readtable(filename);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0099e-e6d6-48f6-9832-fe0b06c44de8",
   "metadata": {},
   "source": [
    "WE can examine the data by viewing the ```f``` variable, and note it is in columns already. we are interested in column 3 and 4, the date and measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da287276-a57c-4e49-93d7-2ac3ab1f7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB\n",
    "date = f{:,3};\n",
    "flow = f{:,4};\n",
    "% Convert the date from a string into datenum object so MATLAB can do date specific work.\n",
    "date = datenum( f{:,3} );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dafe2a-1845-4c51-b8e6-4c12594b4121",
   "metadata": {},
   "source": [
    "### Find Monthly Average\n",
    "We can find a monthly average of our data really roughly using indexes, looping over the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c01d63-a0b2-4707-8d23-6057d24ea7a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (728324531.py, line 5)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfor ii=  1:12\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%MATLAB\n",
    "% Let's say we need a monthly average, we can do that with indexing ?!?\n",
    "months = month(date)\n",
    "\n",
    "for ii=  1:12\n",
    "    indexes = find(months == ii);\n",
    "    Total(ii) = sum( flow(indexes) );\n",
    "    Average(ii) = Total(ii) / length(indexes);\n",
    "end\n",
    "\n",
    "date = datetime( date , 'ConvertFrom', 'datenum' );\n",
    "\n",
    "% For plotting, we just need the month numbers, 1-12, and some\n",
    "% labels for them. MATLAB wouldn't understand where 'Jun' will\n",
    "% go unless we assign 6, then label 6 'Jun'.\n",
    "month_num = [1:12];\n",
    "month_name = {'Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun'...\n",
    "              'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec'};\n",
    "              \n",
    "plot( month_num, Average); title('Monthly Average');\n",
    "xticks(month_num);       % set the ticks to the numbers\n",
    "xticklabels(month_name); % label the numbers with the names!\n",
    "xlabel('Month');\n",
    "ylabel('Average [in]');\n",
    "ylim([0 500]);\n",
    "%save ('save_data.mat', 'date', 'flow' );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614b18bf-83a8-4f93-8b7f-60c1a1fddb63",
   "metadata": {},
   "source": [
    "### Removing NaNs\n",
    "If you scrolled through the data, you noticed there were some missing values, dates, etc. WE need to remove those from our data set. Maybe when we did our average, there was a date with no value, or a NaN. How does averaging work if I add a NaN? How can we find them efficiently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff4d02-bbce-4abc-8e44-8dcc9e970c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB \n",
    "% clean NaNs\n",
    "inan = find(isnan(flow));\n",
    "flow(inan) = [];           % This effectively removes the entry\n",
    "date(inan) = [];           % Do not forget the dates as well\n",
    "\n",
    "% Other equivalent ways of finding nans in dates\n",
    "% isnat == is not a time\n",
    "% if date is a date string\n",
    "\n",
    "% If we did everything correct, then this should be equal to zero\n",
    "inad = find(isnat(date))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdfde0f-cfe9-44bd-aca3-98099dae3f26",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "We look at the data, and there may be time gaps, holes, etc. But we want a nice, steady time series, especially for spectral analysis. We need to give a continuous, constant, spaced time series. Currently, we have holes, as well as temporally inconsistent measurements. \n",
    "\n",
    "To fix this, we are going to make another data set. This one will have perfectly spaced readings, each an hour apart, and we will use our original data to interpolate to the perfectly spaced uniform data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f15f8-75a5-464b-8a23-866a53ecf7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "% Interpolate for hourly times\n",
    "% using interp1\n",
    "\n",
    "firstday = datenum( date(1) );    % first time\n",
    "lastday  = datenum( date(end) );  % last time\n",
    "xq = firstday : 1/24 : lastday;   % make a vector with perfect hour spacing\n",
    "\n",
    "% Interpolate flow to that perfectly spaced vector xq\n",
    "yq = interp1(datenum(date), flow, xq, 'pchip'); \n",
    "close all\n",
    "subplot(2,1,1)\n",
    "xq_datetime = datetime( xq , 'ConvertFrom', 'datenum' );\n",
    "plot(xq_datetime,yq); title('Interpolated Data');\n",
    "subplot(2,1,2)\n",
    "plot(date, flow); title('Original Data');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9ddf9-250f-4de7-aa47-fa31c39fef0a",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n",
    "Sometimes data is noisy. There could be measurement errors, transcription errors, calibration errors, etc. Most data has some natural noise, and to get a clearer picture of any frequencys, you can filter the data.\n",
    "\n",
    "We can create a filter, a moving window, which will smooth our data out. Imagine a 6-hour moving window, where any reading in that window is averaged together. This does that, more technical and mathy, and moves the window in both directions, to prevent any phase shifting effect of our smoothing.\n",
    "\n",
    "Here is a simple example, where we create some noisy data around a  known signal (sin), and then pass a filter over it. We can recover most of the underlying signal from the noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78324a5f-e0d9-47a9-bb1f-83fa8827b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB\n",
    "%% Filters\n",
    "% deciding what filter to use on your data. This is personal, decide what\n",
    "% is the best option. This uses the Butterworth filter \"butter\"\n",
    "\n",
    "t = 0 : 1 : 5*3600;                       % Time, maybe when measurements were taken\n",
    "y = sin(t*2*pi/3600) + randn(size(t));    % Nice cyclic data, with noise added\n",
    "\n",
    "% Setup some values for our filters\n",
    "T = t(2) - t(1);   % 1 second\n",
    "samplingf = 1/T;   % 1 Hz\n",
    "cutoff = 1/(60);   % 1/60 Hz, 1/1 min cutoof frequencies higher than this\n",
    "\n",
    "% First have to setup filter, with parameters A,B\n",
    "[B A] = butter(2, cutoff/(0.5*samplingf), 'low');\n",
    "% Filter the y data, save is as fy\n",
    "fy = filtfilt(B, A, y);\n",
    "\n",
    "%% Plot the results\n",
    "% Original noisy data\n",
    "figure\n",
    "plot(t,y, 'b-x');\n",
    "hold on;\n",
    "% Filtered data, (red line)\n",
    "plot(t,fy,'r-o');\n",
    "hold on;\n",
    "% Original, non-noisy function (yellow line)\n",
    "plot(t, sin(t*2*pi/3600), 'y');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cebc03",
   "metadata": {},
   "source": [
    "Now we can try it with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7815538-b035-4b5a-95ac-ae420e961c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB\n",
    "figure\n",
    "\n",
    "cutoff = 1/7;  % (less than weekly )\n",
    "% Compute sampling interval T based on datetime array\n",
    "T = 1/( datenum(date(2)) - datenum( date(1) ) );\n",
    "\n",
    "% Design Butterworth low-pass filter\n",
    "% The 0.5 adjusts what the window is.\n",
    "[B A] = butter(2, cutoff/(0.5*T), 'low');\n",
    "\n",
    "% Apply the filter forwards and backwards, to try to prevent phase shifting\n",
    "fx = filtfilt(B,A,flow);\n",
    "\n",
    "\n",
    "tiledlayout(2,1)\n",
    "nexttile\n",
    "plot(date,fx, 'b-', 'LineWidth',3); hold on;\n",
    "plot(date, flow, 'r');\n",
    "title('Filtered Data');\n",
    "\n",
    "nexttile\n",
    "plot(date,fx, 'b-', 'LineWidth',3); hold on;\n",
    "plot(date, flow, 'r');\n",
    "title('Zoom in Filtered Data')\n",
    "xlim([date(1000) date(1500)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77162886-bb13-4333-b927-1fdd459b2208",
   "metadata": {},
   "source": [
    "### Spectral Analysis - Fourier Space\n",
    "\n",
    "Now, we can take out filtered data, and analyze it in Fourier (frequency) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace5ea1-0843-45a1-9334-b5fd91eaafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB\n",
    "% % Make date back into a number\n",
    "d = datenum(date);\n",
    "d = d - d(1) + 1;\n",
    "\n",
    "L=length(date);\n",
    "n=2^nextpow2(L);\n",
    "dim=1\n",
    "\n",
    "% Take the Fast-Fourier-Transform to put in phase space\n",
    "orig=fft(fx,n,dim);\n",
    "\n",
    "figure\n",
    "plot(d, orig(1:length(d)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc022240-97a9-4438-9ffa-843ae3db2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB\n",
    "\n",
    "P2 = abs(orig / L);\n",
    "\n",
    "P1 = P2(1:n/2 + 1);\n",
    "P1(2:end-1) = 2*P1(2:end-1);\n",
    "d = datenum(date);\n",
    "d = d - d(1) + 1;\n",
    "figure\n",
    "plot(d(1:500), P1(1:500), 'b-');\n",
    "title('Single-Sided Amplitude Spectrum of flow');\n",
    "xlabel('Time (days since start)');\n",
    "ylabel('|Amplitude|');\n",
    "\n",
    "figure\n",
    "tiledlayout(3,1)\n",
    "nexttile\n",
    "% Original Transformed Data\n",
    "plot(d/86400, orig(1:length(d))); title('Original Transform');\n",
    "nexttile\n",
    "% All Positive\n",
    "plot(d,P2(1:length(d))); title('Positive Transform');\n",
    "xlabel('Time (days since start)');\n",
    "nexttile\n",
    "% MATLAB has built-in functions or other stuff\n",
    "pwelch(flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da876d-7a18-4ec4-af22-ab5e767ab702",
   "metadata": {},
   "source": [
    "### Alternate Data Read for MATLAB\n",
    "\n",
    "Alternate MATLAB note: We can import and text file, and manually extract the data. The script below does that with pattern matching.\n",
    "It is REALLY slow, but a more robust way of explicitly grabbing data from a file, not relying on MATLAB to find the columns of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7acb18-129d-4f66-891d-c7c3e862d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "% MATLAB - Not necessary to run, also SUPER SLOW!!!!!!\n",
    "%raw_data = importdata(filename);\n",
    "%[nr nc] = size(raw_data);\n",
    "%date = zeros(nr,1);\n",
    "%Flow = zeros(nr,1);\n",
    "\n",
    "% Scan the rows for a string, string, string, float, and a string\n",
    "\n",
    "%for ii = 1:nr\n",
    "  %  row = textscan( raw_data{ii}, '%s%s%s%f%s');\n",
    "  %  agency = row{1};\n",
    " %   % Check if the first string says USGS, we know we in the data!\n",
    "%    if strcmp(agency, 'USGS')\n",
    "%        date(ii) = datenum(row{3});\n",
    "%        flow(ii) = row{4};\n",
    "%    end\n",
    "%end\n",
    "\n",
    "%[nr nc] = size(f);\n",
    "%date = zeros( nr, 1);\n",
    "%Q = zeros( nr, 1);\n",
    "\n",
    "% Import the date and time and plot\n",
    "\n",
    "%date =  f{:,3} ;\n",
    "%flow =  f{:,4};\n",
    "\n",
    "%figure\n",
    "%plot(date, flow)\n",
    "%xtickformat('dd-MMM-yyyy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe07af-7e11-4be2-9def-94726e4df699",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "### Raw Data\n",
    "Lets say we are given the task of analyzing the hsitorical data fro mthe water gauge station at the [Prado Dam in Los Angeles](https://waterdata.usgs.gov/monitoring-location/USGS-11074000/#dataTypeId=continuous-00065-0&period=P7D).\n",
    "\n",
    "We want to download the [data](data/PradoDam.txt), clean it, and do some spectral analysis on it to see if there is anything interesting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812aee1-75bd-471d-9cbe-01a881ae97e1",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "If we do a quick check of the file, we note there is a giant header, then some columns of data.\n",
    "```\n",
    "# ---------------------------------- WARNING ----------------------------------------\n",
    "# Some of the data that you have obtained from this U.S. Geological Survey database\n",
    "# may not have received Director's approval. Any such data values are qualified\n",
    "# as provisional and are subject to revision. Provisional data are released on the\n",
    "# condition that neither the USGS nor the United States Government may be held liable\n",
    "# for any damages resulting from its use.\n",
    "#\n",
    "# Additional info: https://help.waterdata.usgs.gov/policies/provisional-data-statement\n",
    "#\n",
    "# File-format description:  https://help.waterdata.usgs.gov/faq/about-tab-delimited-output\n",
    "# Automated-retrieval info: https://help.waterdata.usgs.gov/faq/automated-retrievals\n",
    "#\n",
    "# Contact:   gs-w_support_nwisweb@usgs.gov\n",
    "# retrieved: 2020-04-29 18:30:02 EDT       (caww01)\n",
    "#\n",
    "# Data for the following 1 site(s) are contained in this file\n",
    "#    USGS 11074000 SANTA ANA R BL PRADO DAM CA\n",
    "# -----------------------------------------------------------------------------------\n",
    "#\n",
    "# Data provided for site 11074000\n",
    "#            TS   parameter     statistic     Description\n",
    "#          8183       00060     00003     Discharge, cubic feet per second (Mean)\n",
    "#\n",
    "# Data-value qualification codes included in this output:\n",
    "#     A  Approved for publication -- Processing and review completed.\n",
    "#     P  Provisional data subject to revision.\n",
    "#     e  Value has been estimated.\n",
    "# \n",
    "agency_cd\tsite_no\tdatetime\t8183_00060_00003\t8183_00060_00003_cd\n",
    "5s\t15s\t20d\t14n\t10s\n",
    "USGS\t11074000\t1940-09-30\t51.0\tA\n",
    "USGS\t11074000\t1940-10-01\t47.0\tA\n",
    "USGS\t11074000\t1940-10-02\t47.0\tA\n",
    "USGS\t11074000\t1940-10-03\t47.0\tA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436a73c-82e4-4a58-8733-d40df2a1720b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import datetime\n",
    "from scipy.interpolate import PchipInterpolator\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.dates as mdates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54ec2e-1a18-4fbc-acd0-66869a1686e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === Load the data (equivalent to readtable) ===\n",
    "filename = \"data/PradoDam.txt\"\n",
    "path, full_filename = os.path.split(filename)\n",
    "name, ext = os.path.splitext(full_filename)\n",
    "\n",
    "if ext.lower() != \".txt\":\n",
    "    print(\"Wrong file extension given.\")\n",
    "    raise SystemExit\n",
    "\n",
    "# Read file, skipping lines starting with '#'\n",
    "raw = pd.read_csv(\n",
    "    filename,\n",
    "    comment=\"#\",           # ignore all lines starting with '#'\n",
    "    sep=\"\\t\",              # tab-delimited\n",
    "    header=None,              # first non-comment line is header\n",
    "    dtype=str              # read as strings first (safe)\n",
    ")\n",
    "\n",
    "# First row becomes header, drop second row (format specifiers)\n",
    "raw.columns = raw.iloc[0]       # set column names from first row\n",
    "f = raw.drop(index=0).drop(index=1)  # remove first and second row\n",
    "f = f.reset_index(drop=True)    # reindex after dropping\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adf144-75bd-4402-ab80-a9dfe9a487d8",
   "metadata": {},
   "source": [
    "WE can examine the data by viewing the ```f``` variable, and note it is in columns already. we are interested in column 3 and 4, the date and measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58260f2e-126c-4e41-bf43-1e1b018c4e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "f['datetime'] = pd.to_datetime(f['datetime'])\n",
    "f['8183_00060_00003'] = pd.to_numeric(f['8183_00060_00003'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a59421-d662-4e59-a832-7b3bd5bae27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant data\n",
    "dates = f['datetime']\n",
    "flow = f['8183_00060_00003'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503f36ef-9bed-4c4f-9fc8-fae2aa1bcf1b",
   "metadata": {},
   "source": [
    "### Find Monthly Average\n",
    "We can find a monthly average of our data realyl roughly using indexes, looping over the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e94a79-326b-47ce-84cd-9f86141acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "# === Monthly Averaging ===\n",
    "months = dates.dt.month\n",
    "totals = []\n",
    "averages = []\n",
    "for ii in range(1, 13):\n",
    "    idx = np.where(months == ii)[0]\n",
    "    if len(idx) > 0:\n",
    "        totals.append(np.sum(flow[idx]))\n",
    "        averages.append(np.mean(flow[idx]))\n",
    "    else:\n",
    "        totals.append(np.nan)\n",
    "        averages.append(np.nan)\n",
    "\n",
    "totals = np.array(totals)\n",
    "averages = np.array(averages)\n",
    "\n",
    "# Data\n",
    "% For plotting, we just need the month numbers, 1-12, and some\n",
    "% labels for them. Python wouldn't understand where 'Jun' will\n",
    "% go unless we assign 6, then label 6 'Jun'.\n",
    "month_num = np.arange(1, 13)  # 1 to 12\n",
    "month_name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(month_num, averages, '-o')\n",
    "plt.xticks(month_num, month_name) % Use the numbers, but label with the names\n",
    "plt.title('Monthly Average')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de164e8-6866-4ed0-a953-88a00eed27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09526e9d-4e11-4dcb-9771-7fc29db8fb64",
   "metadata": {},
   "source": [
    "### Removing NaNs\n",
    "If you scrolled through the data, you noticed there were some missing values, dates, etc. WE need to remove those from our data set. Maybe when we did our average, there was a date with no value, or a NaN. How does averaging work if I add a NaN? How can we find them efficiently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e261e7b2-4b9f-4777-89c7-b743ddc3cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python \n",
    "# Clean NaNs\n",
    "nan_mask = np.isnan(flow)\n",
    "dates = dates[~nan_mask]\n",
    "flow = flow[~nan_mask]\n",
    "\n",
    "# If all of the NaNs are gone, this should return a zero\n",
    "sum(np.isnan(flow))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d68181-8104-4e94-8a4c-b9818ea74066",
   "metadata": {},
   "source": [
    "### Interpolation\n",
    "We look at the data, and there may be time gaps, holes, etc. But we want a nice, steady time series, especially for spectral analysis. We need to give a continuous, constant, spaced time series. Currently, we have holes, as well as temporally inconsistent measurements. \n",
    "\n",
    "To fix this, we are going to make another data set. This one will have perfectly spaced readings, each an hour apart, and we will use our original data to interpolate to the perfectly spaced uniform data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c18cc6-167f-4b21-abce-310fce1ca726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Interpolation to hourly ===\n",
    "# Convert to numeric days since epoch for interpolation\n",
    "# Is there a nicer way to do this?\n",
    "\n",
    "datenum = dates.map(pd.Timestamp.toordinal) + (\n",
    "    dates.dt.hour / 24 + dates.dt.minute / 1440 + dates.dt.second / 86400\n",
    ")\n",
    "\n",
    "firstday = datenum.iloc[0]\n",
    "lastday = datenum.iloc[-1]\n",
    "xq = np.arange(firstday, lastday, 1/24)\n",
    "\n",
    "% Creaet the interpolator\n",
    "pchip_interp = PchipInterpolator(datenum, flow)\n",
    "% Interpolate flow to the perfect vector xq\n",
    "yq = pchip_interp(xq)\n",
    "\n",
    "# Plotting\n",
    "plt.close('all')\n",
    "fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
    "xq_datetime = pd.to_datetime(xq)  # convert back to datetime for plotting\n",
    "axs[0].plot(xq_datetime, yq)\n",
    "axs[0].set_title(\"Interpolated Data (Hourly)\")\n",
    "axs[0].grid()\n",
    "\n",
    "axs[1].plot(dates, flow, 'r')\n",
    "axs[1].set_title(\"Original Data (Daily)\")\n",
    "axs[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca497800-59f7-4a97-9616-57b3da822073",
   "metadata": {},
   "source": [
    "### Filtering Data\n",
    "\n",
    "Sometimes data is noisy. There could be measurement errors, transcription errors, calibration errors, etc. Most data has some natural noise, and to get a clearer picture of any frequencys, you can filter the data.\n",
    "\n",
    "We can create a filter, a moving window, which will smooth our data out. Imagine a 6-hour moving window, where any reading in that window is averaged together. This does that, more technical and mathy, and moves the window in both directions, to prevent any phase shifting effect of our smoothing.\n",
    "\n",
    "Here is a simple example, where we create some noisy data around a  known signal (sin), and then pass a filter over it. We can recover most of the underlying signal from the noise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b24c27-9200-4b89-adfc-f5327b4cc568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "# Filters\n",
    "# deciding what filter to use on your data. This is personal, decide what\n",
    "# is the best option. This uses the Butterworth filter \"butter\"\n",
    "t = np.arange(0, 5*3600 + 1, 1)  # from 0 to 5 hours, 1-second intervals\n",
    "\n",
    "# Nice cyclic data, with noise added\n",
    "y = np.sin(t * 2 * np.pi / 3600) + np.random.randn(len(t))\n",
    "\n",
    "# Setup some values for our filters\n",
    "T = t[1] - t[0]          # 1 second\n",
    "samplingf = 1 / T        # 1 Hz\n",
    "cutoff = 1 / 60          # 1/60 Hz, 1 minute cutoff frequency\n",
    "\n",
    "# Design Butterworth low-pass filter\n",
    "b, a = butter(2, cutoff / (0.5 * samplingf), btype='low')\n",
    "\n",
    "# Filter the data both ways to ptry to prevent phase shift, also \n",
    "# called zero-phase filtering\n",
    "fy = filtfilt(b, a, y)\n",
    "\n",
    "# --- Plot the results ---\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot every 10th number, so we can see the outliers\n",
    "plt.plot(t[::10], y[::10], 'b-x', label='Noisy Data')\n",
    "plt.plot(t, fy, 'r-o', label='Filtered Data')\n",
    "plt.plot(t, np.sin(t * 2 * np.pi / 3600), 'y', label='Original Signal')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Butterworth Low-Pass Filter Example')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17cf8eb-60af-4e48-8d91-86f6c3802391",
   "metadata": {},
   "source": [
    "Now we can try it with our data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a789ef-9b6b-4933-8e5f-04ea47a9765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "# --- Filter setup ---\n",
    "cutoff = 1 / 7  # less than weekly\n",
    "\n",
    "# Compute sampling interval T based on datetime array\n",
    "# Convert datetime to matplotlib's float days\n",
    "date_num = mdates.date2num(dates)  # converts datetime to float days\n",
    "T = 1 / (date_num[1] - date_num[0])  # sampling frequency in 1/days\n",
    "\n",
    "# Design Butterworth low-pass filter\n",
    "# The 0.5 adjusts what the window is.\n",
    "b, a = butter(2, cutoff / (0.5* T), btype='low')\n",
    "\n",
    "# Apply filter forwards and backwards (zero-phase)\n",
    "fx = filtfilt(b, a, flow)\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 8), constrained_layout=True)\n",
    "\n",
    "# First plot: full series\n",
    "axs[0].plot(dates, fx, 'b-', linewidth=3, label='Filtered')\n",
    "axs[0].plot(dates, flow, 'r', label='Original')\n",
    "axs[0].set_title('Filtered Data')\n",
    "axs[0].legend()\n",
    "axs[0].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Second plot: zoomed in\n",
    "axs[1].plot(dates, fx, 'b-', linewidth=3, label='Filtered')\n",
    "axs[1].plot(dates, flow, 'r', linewidth=0.75,label='Original')\n",
    "axs[1].set_title('Zoom in Filtered Data')\n",
    "axs[1].set_xlim( [datetime.date(1980,1,1), datetime.date(1981,12,1)] )\n",
    "axs[1].legend()\n",
    "axs[1].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77989da-0ed9-4350-b2ba-11d2a4ff777a",
   "metadata": {},
   "source": [
    "### Spectral Analysis - Fourier Space\n",
    "\n",
    "Now, we can take out filtered data, and analyze it in Fourier (frequency) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b75c49e-03ab-47e8-b6d5-ef82ce0ac0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "# --- Convert date to numeric like MATLAB datenum ---\n",
    "d = mdates.date2num(dates)   # convert datetime array to float days\n",
    "d = d - d[0] + 1           # shift so first date is day 1\n",
    "\n",
    "L = len(dates)\n",
    "# nextpow2 equivalent\n",
    "n = 2 ** int(np.ceil(np.log2(L)))\n",
    "dim = 0  # NumPy uses axis=0 for rows, like MATLAB dim=1\n",
    "\n",
    "# Take FFT along the chosen dimension\n",
    "orig = np.fft.fft(fx, n=n, axis=dim)\n",
    "\n",
    "# --- Plot the result ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d, orig[:len(d)].real)  # plot real part (imag part is usually symmetric)\n",
    "plt.xlabel(\"Time (days since start)\")\n",
    "plt.ylabel(\"FFT Amplitude (Real Part)\")\n",
    "plt.title(\"FFT of Filtered Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fd7413-0aef-47b3-922a-4796f5df3394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ca79b-da04-41fc-b7d7-a0839536fede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "\n",
    "from scipy.signal import welch\n",
    "\n",
    "date=dates\n",
    "# --- Compute FFT quantities ---\n",
    "L = len(date)\n",
    "P2 = np.abs(orig / L)\n",
    "\n",
    "# MATLAB uses n/2 + 1 for positive frequencies\n",
    "P1 = P2[: int(n // 2) + 1].copy()\n",
    "P1[1:-1] = 2 * P1[1:-1]\n",
    "\n",
    "# Convert date to numeric like MATLAB datenum\n",
    "d = mdates.date2num(date)\n",
    "d = d - d[0] + 1  # start at 1\n",
    "\n",
    "# --- Plot first figure: first 500 points of positive FFT spectrum ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(d[:500], P1[:500], 'b-')\n",
    "plt.xlabel(\"Time (days since start)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.title(\"Single-Sided Amplitude Spectrum\")\n",
    "plt.show()\n",
    "\n",
    "# --- Tiled layout (3 subplots) ---\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 10), constrained_layout=True)\n",
    "\n",
    "# 1. Original transformed data\n",
    "axs[0].plot(d / 86400, orig[:len(d)].real)  # divide by 86400 if you want seconds -> days\n",
    "axs[0].set_title('Original Transform')\n",
    "\n",
    "# 2. All positive transform\n",
    "axs[1].plot(d, P2[:len(d)])\n",
    "axs[1].set_title('Positive Transform')\n",
    "\n",
    "# 3. Welch Power Spectral Density\n",
    "f, Pxx = welch(flow, fs=1.0)  # fs=1.0 assumes 1 sample per day (adjust if different)\n",
    "axs[2].semilogy(f, Pxx)\n",
    "axs[2].set_title('Welch Power Spectral Density')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d3464d-4083-4d18-80ec-02caaa457b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
